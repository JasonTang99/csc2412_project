{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import opacus\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "# Random Seeding\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 28\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_1=64, hidden_2=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size**2, hidden_1, bias=False)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2, bias=False)\n",
    "        self.fc3 = nn.Linear(hidden_2, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, image_size**2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Generator similar to DCGAN\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=100, ngf=32, nc=1):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Setup Generator Weight Initialization\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Setup model and optimizer\n",
    "hidden_1 = 64\n",
    "hidden_2 = 16\n",
    "model = Discriminator(hidden_1, hidden_2).to(device)\n",
    "\n",
    "# Initialize weights\n",
    "netG.apply(weights_init)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "data_loader = train_loader\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "0.703366756439209\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(data_loader))[0].to(device)\n",
    "print(sample.shape)\n",
    "output = model(sample)\n",
    "print(output.shape)\n",
    "target = torch.ones((sample.shape[0], 1)).to(device)\n",
    "print(target.shape)\n",
    "loss = loss_fn(output.flatten(), target.flatten())\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784]) 7.840001106262207 7.840001106262207 0 64 784\n",
      "torch.Size([16, 64]) 7.840001106262207 5.0176005363464355 1024 16 64\n",
      "torch.Size([1, 16]) 7.840001106262207 0.8028160929679871 1040 1 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "163.0720230102539"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given parameter clip bounds c_p, compute maximal ReLU activation bounds B_sigma\n",
    "def compute_ReLU_bounds(model, c_p, input_size=(784,), input_bounds=1.0):\n",
    "    sample = torch.ones(input_size).to(device) * input_bounds\n",
    "    max_val = 0.0\n",
    "    sum_mk_mkp1 = 0\n",
    "    skip_first = True\n",
    "\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            W = torch.ones_like(layer.weight) * c_p\n",
    "            sample = W @ sample\n",
    "            \n",
    "            max_val = max(max_val, sample.max().detach().item())\n",
    "            \n",
    "            if skip_first:\n",
    "                skip_first = False\n",
    "            else:\n",
    "                sum_mk_mkp1 += W.shape[0] * W.shape[1]\n",
    "                # sum_mk_mkp1 += (W.shape[0] + 1) * (W.shape[1] + 1)\n",
    "            print(layer.weight.shape, max_val, sample.max().detach().item(), sum_mk_mkp1, W.shape[0], W.shape[1])\n",
    "\n",
    "    return max_val, sum_mk_mkp1\n",
    "\n",
    "# Setup parameters for Gradient Clip Calculation\n",
    "c_p = 0.01\n",
    "B_sigma_p = 1.0\n",
    "B_sigma, sum_mk_mkp1 = compute_ReLU_bounds(model, c_p)\n",
    "\n",
    "c_g = 2 * c_p * B_sigma * (B_sigma_p ** 2) * sum_mk_mkp1\n",
    "c_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grad_norm(model):\n",
    "    gradient_norm = 0\n",
    "    for param in model.parameters():\n",
    "        gradient_norm += torch.sum(param.grad ** 2)\n",
    "    gradient_norm = gradient_norm ** 0.5\n",
    "    return gradient_norm\n",
    "\n",
    "def param_grad_l1(model):\n",
    "    gradient_norm = 0\n",
    "    for param in model.parameters():\n",
    "        gradient_norm += param.grad.abs().sum().item()\n",
    "    return gradient_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Max Norm: tensor(12.1363, device='cuda:0') 0 0\n",
      "Max Norm: tensor(12.1363, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "max_norm = 0\n",
    "first = True\n",
    "epsilon = 1e-7\n",
    "for idx in range(1000):\n",
    "    if first:\n",
    "        fill_val = c_p\n",
    "        model.fc1.weight.data.fill_(fill_val)\n",
    "        model.fc2.weight.data.fill_(fill_val)\n",
    "        model.fc3.weight.data.fill_(fill_val)\n",
    "        first = False\n",
    "    else:\n",
    "        # Randomize model weights (clip to c_p)\n",
    "        model.fc1.weight.data = torch.clamp(torch.randn_like(model.fc1.weight), -c_p, c_p)\n",
    "        model.fc2.weight.data = torch.clamp(torch.randn_like(model.fc2.weight), -c_p, c_p)\n",
    "        model.fc3.weight.data = torch.clamp(torch.randn_like(model.fc3.weight), -c_p, c_p)\n",
    "    \n",
    "    # Print min max of model weights\n",
    "    assert model.fc1.weight.min().item() >= -c_p - epsilon\n",
    "    assert model.fc1.weight.max().item() <= c_p + epsilon\n",
    "    assert model.fc2.weight.min().item() >= -c_p - epsilon\n",
    "    assert model.fc2.weight.max().item() <= c_p + epsilon\n",
    "    assert model.fc3.weight.min().item() >= -c_p - epsilon\n",
    "    assert model.fc3.weight.max().item() <= c_p + epsilon\n",
    "    \n",
    "    for c in range(2):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # random sample\n",
    "        sample = (torch.rand(784) > 0.1).to(torch.float32).to(device)\n",
    "        # sample = torch.ones(784).to(device)\n",
    "        assert sample.min().item() >= 0.0\n",
    "        assert sample.max().item() <= 1.0\n",
    "\n",
    "        sample_out = model(sample)\n",
    "\n",
    "        # Assert all activations are below B_sigma\n",
    "        activated_1 = F.relu(model.fc1(sample))\n",
    "        activated_2 = F.relu(model.fc2(activated_1))\n",
    "        activated_3 = torch.sigmoid(model.fc3(activated_2))\n",
    "        assert activated_1.max().item() <= B_sigma\n",
    "        assert activated_2.max().item() <= B_sigma\n",
    "        assert activated_3.max().item() <= B_sigma\n",
    "        \n",
    "        target = torch.ones((1, 1)).to(device) * c\n",
    "\n",
    "        loss = loss_fn(sample_out, target)\n",
    "        loss.backward()\n",
    "\n",
    "        grad_norm = param_grad_norm(model)\n",
    "        # l1_norm = param_grad_l1(model)\n",
    "        if grad_norm > max_norm:\n",
    "            max_norm = grad_norm\n",
    "            # print(\"New L1 Norm:\", l1_norm, idx, c)\n",
    "            print(\"New Max Norm:\", max_norm, idx, c)\n",
    "    # break\n",
    "    if max_norm > c_g:\n",
    "        print(\"Max Norm Exceeded\")\n",
    "        break\n",
    "\n",
    "print(\"Max Norm:\", max_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logical and physical batch sizes\n",
    "BATCH_SIZE = 64\n",
    "MAX_PHYSICAL_BATCH_SIZE = 64\n",
    "\n",
    "# Privacy parameters\n",
    "EPSILON = 50.0\n",
    "DELTA = 1e-5\n",
    "MAX_GRAD_NORM = 1.2\n",
    "c_p = 0.01\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "n_d = 5 # number of discriminator updates per generator update\n",
    "n_g = 5e5 # number of generator updates\n",
    "LR = 5e-5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Probability: 0.008533333333333334\n"
     ]
    }
   ],
   "source": [
    "M = len(train_set)\n",
    "\n",
    "sample_prob = BATCH_SIZE / M\n",
    "print(\"Sample Probability:\", sample_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before make_private(). Model:<class 'opacus.grad_sample.grad_sample_module.GradSampleModule'>, \n",
      "Optimizer:<class 'opacus.optimizers.optimizer.DPOptimizer'>, \n",
      "DataLoader:<class 'opacus.data_loader.DPDataLoader'>\n",
      "====================\n",
      "After make_private(). Model:<class 'opacus.grad_sample.grad_sample_module.GradSampleModule'>, \n",
      "Optimizer:<class 'opacus.optimizers.optimizer.DPOptimizer'>, \n",
      "DataLoader:<class 'opacus.data_loader.DPDataLoader'>\n"
     ]
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "print(\n",
    "    f\"Before make_private(). \"\n",
    "    f\"Model:{type(model)}, \\nOptimizer:{type(optimizer)}, \\nDataLoader:{type(data_loader)}\"\n",
    ")\n",
    "\n",
    "model, optimizer, data_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=data_loader,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    "    noise_multiplier=1.0,\n",
    ")\n",
    "\n",
    "print(\"=\"*20)\n",
    "\n",
    "print(\n",
    "    f\"After make_private(). \"\n",
    "    f\"Model:{type(model)}, \\nOptimizer:{type(optimizer)}, \\nDataLoader:{type(data_loader)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/p2/playground.ipynb Cell 8\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                     epoch, batch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                     \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m batch_idx \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader), loss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m         epoch, \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), loss\u001b[39m.\u001b[39mitem()))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m train(model, optimizer, loss_fn, data_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/home/jason/p2/playground.ipynb Cell 8\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m         \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                 epoch, batch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                 \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m batch_idx \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader), loss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     epoch, \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), loss\u001b[39m.\u001b[39mitem()))\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "def train(model, optimizer, loss_fn, data_loader, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            print(output.shape, target.shape)\n",
    "            break\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print max gradient\n",
    "            max_grad = 0.0\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    max_grad = max(max_grad, param.grad.max().detach().item())\n",
    "            print(max_grad)\n",
    "            if max_grad > c_g:\n",
    "                print(\"Gradient clipping required\")\n",
    "                break\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "                    100. * batch_idx / len(data_loader), loss.item()))\n",
    "    \n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, len(data_loader.dataset), len(data_loader.dataset),\n",
    "        100. * len(data_loader.dataset) / len(data_loader.dataset), loss.item()))\n",
    "        \n",
    "train(model, optimizer, loss_fn, data_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer:  torch.Size([64, 784]) torch.Size([64])\n",
      "Linear layer:  torch.Size([10, 64]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.modules()):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(\"Linear layer: \", layer.weight.shape, layer.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before make_private(). Model:<class '__main__.MLP'>, \n",
      "Optimizer:<class 'torch.optim.sgd.SGD'>, \n",
      "DataLoader:<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "====================\n",
      "After make_private(). Model:<class 'opacus.grad_sample.grad_sample_module.GradSampleModule'>, \n",
      "Optimizer:<class 'opacus.optimizers.optimizer.DPOptimizer'>, \n",
      "DataLoader:<class 'opacus.data_loader.DPDataLoader'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
