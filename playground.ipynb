{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import opacus\n",
    "from opacus import PrivacyEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "# Random Seeding\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup simple FC model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Setup model and optimizer\n",
    "model = Discriminator().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "data_loader = train_loader\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(data_loader))[0]\n",
    "print(sample.shape)\n",
    "output = model(sample.to(device))\n",
    "print(output.shape)\n",
    "target = torch.ones((sample.shape[0], 1)).to(device)\n",
    "print(target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5859, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(output.flatten(), target.flatten())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes\n",
    "model.fc1.weight.shape, model.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "0.7850000262260437 0.7850000262260437\n",
      "torch.Size([1, 64])\n",
      "0.7850000262260437 0.05124000459909439\n",
      "1 64 130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20410000681877136"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given parameter clip bounds c_p, compute maximal ReLU activation bounds B_sigma\n",
    "def compute_ReLU_bounds(model, c_p, input_size=(784,), input_bounds=1.0):\n",
    "    sample = torch.ones(input_size).to(device) * input_bounds\n",
    "    max_val = 0.0\n",
    "    sum_mk_mkp1 = 0\n",
    "    skip_first = True\n",
    "\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            print(layer.weight.shape)\n",
    "\n",
    "            W = torch.ones_like(layer.weight) * c_p\n",
    "            b = torch.ones_like(layer.bias) * c_p\n",
    "            sample = W @ sample + b\n",
    "            sample_max = sample.max().detach().item()\n",
    "            if max_val < sample_max:\n",
    "                max_val = sample_max\n",
    "            print(max_val, sample_max)\n",
    "            \n",
    "            if skip_first:\n",
    "                skip_first = False\n",
    "            else:\n",
    "                # sum_mk_mkp1 += W.shape[0] * W.shape[1]\n",
    "                sum_mk_mkp1 += (W.shape[0] + 1) * (W.shape[1] + 1)\n",
    "                print(W.shape[0], W.shape[1], sum_mk_mkp1)\n",
    "    return max_val, sum_mk_mkp1\n",
    "\n",
    "# Setup parameters for Gradient Clip Calculation\n",
    "c_p = 0.001\n",
    "B_sigma_p = 1.0\n",
    "B_sigma, sum_mk_mkp1 = compute_ReLU_bounds(model, c_p)\n",
    "\n",
    "c_g = 2 * c_p * B_sigma * (B_sigma_p ** 2) * sum_mk_mkp1\n",
    "c_g\n",
    "\n",
    "# 3.2572895401924264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grad_norm(model):\n",
    "    gradient_norm = 0\n",
    "    for param in model.parameters():\n",
    "        gradient_norm += param.grad.norm().item() ** 2\n",
    "    gradient_norm = gradient_norm ** 0.5\n",
    "    return gradient_norm\n",
    "\n",
    "def param_grad_l1(model):\n",
    "    gradient_norm = 0\n",
    "    for param in model.parameters():\n",
    "        gradient_norm += param.grad.abs().sum().item()\n",
    "    return gradient_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "for idx in range(1000):\n",
    "    if first:\n",
    "        fill_val = c_p\n",
    "        model.fc1.weight.data.fill_(fill_val)\n",
    "        model.fc1.bias.data.fill_(fill_val)\n",
    "        model.fc2.weight.data.fill_(fill_val)\n",
    "        model.fc2.bias.data.fill_(fill_val)\n",
    "        first = False\n",
    "    else:\n",
    "        # Randomize model weights (clip to c_p)\n",
    "        model.fc1.weight.data = torch.clamp(torch.randn_like(model.fc1.weight), -c_p, c_p)\n",
    "        model.fc1.bias.data = torch.clamp(torch.randn_like(model.fc1.bias), -c_p, c_p)\n",
    "        model.fc2.weight.data = torch.clamp(torch.randn_like(model.fc2.weight), -c_p, c_p)\n",
    "        model.fc2.bias.data = torch.clamp(torch.randn_like(model.fc2.bias), -c_p, c_p)\n",
    "\n",
    "    # bias to 0\n",
    "    model.fc1.bias.data.fill_(0)\n",
    "    model.fc2.bias.data.fill_(0)\n",
    "\n",
    "    for c in range(2):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # random sample\n",
    "        sample = (torch.rand(784) > 0.1).to(torch.float32).to(device)\n",
    "        # sample = torch.ones(784).to(device)\n",
    "        sample_out = model(sample)\n",
    "\n",
    "        # Assert all activations are below B_sigma\n",
    "        activated_1 = F.relu(model.fc1(sample))\n",
    "        activated_2 = torch.sigmoid(model.fc2(activated_1))\n",
    "        assert activated_1.max().item() < B_sigma\n",
    "        assert activated_2.max().item() < B_sigma\n",
    "\n",
    "        target = torch.ones((1, 1)).to(device) * c\n",
    "\n",
    "        loss = loss_fn(sample_out, target)\n",
    "        loss.backward()\n",
    "\n",
    "        # print(model.fc1.bias.grad.max().item(), model.fc1.bias.grad.min().item())\n",
    "        # print(model.fc2.bias.grad)\n",
    "\n",
    "        grad_norm = param_grad_norm(model)\n",
    "        # grad_norm = param_grad_l1(model)\n",
    "        # print(\"Class:\", c, \"---\", \"Grad Norm:\", grad_norm)\n",
    "        if grad_norm > max_norm:\n",
    "            max_norm = grad_norm\n",
    "            print(\"New Max Norm:\", max_norm, idx, c)\n",
    "    \n",
    "    # if max_norm > c_g:\n",
    "    #     print(\"Max Norm Exceeded\")\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7850000262260437"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2572895401924264"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 --- 0.0\n",
      "Class: 1 --- 2.802596928649634e-45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/p2/playground.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m sample \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m784\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m sample \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(model\u001b[39m.\u001b[39;49mfc1(sample))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m sample \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfc2(sample)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m sample \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# Fill weights and biases to c_p\n",
    "fill_val = c_p\n",
    "model.fc1.weight.data.fill_(fill_val)\n",
    "model.fc1.bias.data.fill_(fill_val)\n",
    "model.fc2.weight.data.fill_(fill_val)\n",
    "model.fc2.bias.data.fill_(fill_val)\n",
    "\n",
    "\n",
    "for c in range(10):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample = torch.ones(784).to(device)\n",
    "    sample = F.relu(model.fc1(sample))\n",
    "    sample = model.fc2(sample)\n",
    "    sample = sample.unsqueeze(0)\n",
    "\n",
    "    target = torch.tensor([c]).to(device)\n",
    "\n",
    "    loss = loss_fn(sample, target)\n",
    "    loss.backward()\n",
    "\n",
    "    print(\"Class:\", c, \"---\", param_grad_norm(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/p2/playground.ipynb Cell 8\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                     epoch, batch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                     \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m batch_idx \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader), loss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m         epoch, \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), loss\u001b[39m.\u001b[39mitem()))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m train(model, optimizer, loss_fn, data_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/home/jason/p2/playground.ipynb Cell 8\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m         \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                 epoch, batch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                 \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m batch_idx \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader), loss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     epoch, \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), loss\u001b[39m.\u001b[39mitem()))\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "def train(model, optimizer, loss_fn, data_loader, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            print(output.shape, target.shape)\n",
    "            break\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print max gradient\n",
    "            max_grad = 0.0\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    max_grad = max(max_grad, param.grad.max().detach().item())\n",
    "            print(max_grad)\n",
    "            if max_grad > c_g:\n",
    "                print(\"Gradient clipping required\")\n",
    "                break\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "                    100. * batch_idx / len(data_loader), loss.item()))\n",
    "    \n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, len(data_loader.dataset), len(data_loader.dataset),\n",
    "        100. * len(data_loader.dataset) / len(data_loader.dataset), loss.item()))\n",
    "        \n",
    "train(model, optimizer, loss_fn, data_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer:  torch.Size([64, 784]) torch.Size([64])\n",
      "Linear layer:  torch.Size([10, 64]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.modules()):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(\"Linear layer: \", layer.weight.shape, layer.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before make_private(). Model:<class '__main__.MLP'>, \n",
      "Optimizer:<class 'torch.optim.sgd.SGD'>, \n",
      "DataLoader:<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "====================\n",
      "After make_private(). Model:<class 'opacus.grad_sample.grad_sample_module.GradSampleModule'>, \n",
      "Optimizer:<class 'opacus.optimizers.optimizer.DPOptimizer'>, \n",
      "DataLoader:<class 'opacus.data_loader.DPDataLoader'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "print(\n",
    "    f\"Before make_private(). \"\n",
    "    f\"Model:{type(model)}, \\nOptimizer:{type(optimizer)}, \\nDataLoader:{type(data_loader)}\"\n",
    ")\n",
    "\n",
    "model, optimizer, data_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=data_loader,\n",
    "    max_grad_norm=1.0,\n",
    "    noise_multiplier=1.0,\n",
    ")\n",
    "\n",
    "print(\"=\"*20)\n",
    "\n",
    "print(\n",
    "    f\"After make_private(). \"\n",
    "    f\"Model:{type(model)}, \\nOptimizer:{type(optimizer)}, \\nDataLoader:{type(data_loader)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
