{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import opacus\n",
    "from opacus import PrivacyEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'latent_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Read Data \u001b[39;00m\n\u001b[1;32m      2\u001b[0m columns\u001b[39m=\u001b[39m[\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhiddens\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnoise_multiplier\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mactivation\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mc_p\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFID\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_fp\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mlatent_results.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'latent_results.csv'"
     ]
    }
   ],
   "source": [
    "# Read Data \n",
    "columns=[\n",
    "    \"hiddens\", \"noise_multiplier\", \"activation\", \n",
    "    \"n_d\", \"c_p\", \"FID\", \"model_fp\"\n",
    "]\n",
    "df = pd.read_csv(\"latent_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "# Random Seeding\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup simple FC model\n",
    "class Discriminator_FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_FC, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Setup model and optimizer\n",
    "model = Discriminator_FC().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "data_loader = train_loader\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(data_loader))[0]\n",
    "print(sample.shape)\n",
    "output = model(sample.to(device))\n",
    "print(output.shape)\n",
    "target = torch.ones((sample.shape[0], 1)).to(device)\n",
    "print(target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5859, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(output.flatten(), target.flatten())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes\n",
    "model.fc1.weight.shape, model.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "0.7850000262260437 0.7850000262260437\n",
      "torch.Size([1, 64])\n",
      "0.7850000262260437 0.05124000459909439\n",
      "1 64 130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20410000681877136"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given parameter clip bounds c_p, compute maximal ReLU activation bounds B_sigma\n",
    "def compute_ReLU_bounds(model, c_p, input_size=(784,), input_bounds=1.0):\n",
    "    sample = torch.ones(input_size).to(device) * input_bounds\n",
    "    max_val = 0.0\n",
    "    sum_mk_mkp1 = 0\n",
    "    skip_first = True\n",
    "\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            print(layer.weight.shape)\n",
    "\n",
    "            W = torch.ones_like(layer.weight) * c_p\n",
    "            b = torch.ones_like(layer.bias) * c_p\n",
    "            sample = W @ sample + b\n",
    "            sample_max = sample.max().detach().item()\n",
    "            if max_val < sample_max:\n",
    "                max_val = sample_max\n",
    "            print(max_val, sample_max)\n",
    "            \n",
    "            if skip_first:\n",
    "                skip_first = False\n",
    "            else:\n",
    "                # sum_mk_mkp1 += W.shape[0] * W.shape[1]\n",
    "                sum_mk_mkp1 += (W.shape[0] + 1) * (W.shape[1] + 1)\n",
    "                print(W.shape[0], W.shape[1], sum_mk_mkp1)\n",
    "    return max_val, sum_mk_mkp1\n",
    "\n",
    "# Setup parameters for Gradient Clip Calculation\n",
    "c_p = 0.001\n",
    "B_sigma_p = 1.0\n",
    "B_sigma, sum_mk_mkp1 = compute_ReLU_bounds(model, c_p)\n",
    "\n",
    "c_g = 2 * c_p * B_sigma * (B_sigma_p ** 2) * sum_mk_mkp1\n",
    "c_g\n",
    "\n",
    "# 3.2572895401924264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grad_norm(model):\n",
    "    gradient_norm = 0\n",
    "    for param in model.parameters():\n",
    "        gradient_norm += param.grad.norm().item() ** 2\n",
    "    gradient_norm = gradient_norm ** 0.5\n",
    "    return gradient_norm\n",
    "\n",
    "def param_grad_l1(model):\n",
    "    gradient_norm = 0\n",
    "    for param in model.parameters():\n",
    "        gradient_norm += param.grad.abs().sum().item()\n",
    "    return gradient_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "for idx in range(1000):\n",
    "    if first:\n",
    "        fill_val = c_p\n",
    "        model.fc1.weight.data.fill_(fill_val)\n",
    "        model.fc1.bias.data.fill_(fill_val)\n",
    "        model.fc2.weight.data.fill_(fill_val)\n",
    "        model.fc2.bias.data.fill_(fill_val)\n",
    "        first = False\n",
    "    else:\n",
    "        # Randomize model weights (clip to c_p)\n",
    "        model.fc1.weight.data = torch.clamp(torch.randn_like(model.fc1.weight), -c_p, c_p)\n",
    "        model.fc1.bias.data = torch.clamp(torch.randn_like(model.fc1.bias), -c_p, c_p)\n",
    "        model.fc2.weight.data = torch.clamp(torch.randn_like(model.fc2.weight), -c_p, c_p)\n",
    "        model.fc2.bias.data = torch.clamp(torch.randn_like(model.fc2.bias), -c_p, c_p)\n",
    "\n",
    "    # bias to 0\n",
    "    model.fc1.bias.data.fill_(0)\n",
    "    model.fc2.bias.data.fill_(0)\n",
    "\n",
    "    for c in range(2):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # random sample\n",
    "        sample = (torch.rand(784) > 0.1).to(torch.float32).to(device)\n",
    "        # sample = torch.ones(784).to(device)\n",
    "        sample_out = model(sample)\n",
    "\n",
    "        # Assert all activations are below B_sigma\n",
    "        activated_1 = F.relu(model.fc1(sample))\n",
    "        activated_2 = torch.sigmoid(model.fc2(activated_1))\n",
    "        assert activated_1.max().item() < B_sigma\n",
    "        assert activated_2.max().item() < B_sigma\n",
    "\n",
    "        target = torch.ones((1, 1)).to(device) * c\n",
    "\n",
    "        loss = loss_fn(sample_out, target)\n",
    "        loss.backward()\n",
    "\n",
    "        # print(model.fc1.bias.grad.max().item(), model.fc1.bias.grad.min().item())\n",
    "        # print(model.fc2.bias.grad)\n",
    "\n",
    "        grad_norm = param_grad_norm(model)\n",
    "        # grad_norm = param_grad_l1(model)\n",
    "        # print(\"Class:\", c, \"---\", \"Grad Norm:\", grad_norm)\n",
    "        if grad_norm > max_norm:\n",
    "            max_norm = grad_norm\n",
    "            print(\"New Max Norm:\", max_norm, idx, c)\n",
    "    \n",
    "    # if max_norm > c_g:\n",
    "    #     print(\"Max Norm Exceeded\")\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7850000262260437"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2572895401924264"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0 --- 0.0\n",
      "Class: 1 --- 2.802596928649634e-45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/p2/playground.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m sample \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m784\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m sample \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(model\u001b[39m.\u001b[39;49mfc1(sample))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m sample \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfc2(sample)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m sample \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# Fill weights and biases to c_p\n",
    "fill_val = c_p\n",
    "model.fc1.weight.data.fill_(fill_val)\n",
    "model.fc1.bias.data.fill_(fill_val)\n",
    "model.fc2.weight.data.fill_(fill_val)\n",
    "model.fc2.bias.data.fill_(fill_val)\n",
    "\n",
    "\n",
    "for c in range(10):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample = torch.ones(784).to(device)\n",
    "    sample = F.relu(model.fc1(sample))\n",
    "    sample = model.fc2(sample)\n",
    "    sample = sample.unsqueeze(0)\n",
    "\n",
    "    target = torch.tensor([c]).to(device)\n",
    "\n",
    "    loss = loss_fn(sample, target)\n",
    "    loss.backward()\n",
    "\n",
    "    print(\"Class:\", c, \"---\", param_grad_norm(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "torch.Size([64, 10]) torch.Size([64])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/p2/playground.ipynb Cell 8\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                     epoch, batch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                     \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m batch_idx \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader), loss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m         epoch, \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), loss\u001b[39m.\u001b[39mitem()))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m train(model, optimizer, loss_fn, data_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/home/jason/p2/playground.ipynb Cell 8\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m         \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                 epoch, batch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                 \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m batch_idx \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader), loss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     epoch, \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset),\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B142.198.206.105/home/jason/p2/playground.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader\u001b[39m.\u001b[39mdataset), loss\u001b[39m.\u001b[39mitem()))\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "def train(model, optimizer, loss_fn, data_loader, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            print(output.shape, target.shape)\n",
    "            break\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print max gradient\n",
    "            max_grad = 0.0\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    max_grad = max(max_grad, param.grad.max().detach().item())\n",
    "            print(max_grad)\n",
    "            if max_grad > c_g:\n",
    "                print(\"Gradient clipping required\")\n",
    "                break\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "                    100. * batch_idx / len(data_loader), loss.item()))\n",
    "    \n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, len(data_loader.dataset), len(data_loader.dataset),\n",
    "        100. * len(data_loader.dataset) / len(data_loader.dataset), loss.item()))\n",
    "        \n",
    "train(model, optimizer, loss_fn, data_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer:  torch.Size([64, 784]) torch.Size([64])\n",
      "Linear layer:  torch.Size([10, 64]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.modules()):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(\"Linear layer: \", layer.weight.shape, layer.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before make_private(). Model:<class '__main__.MLP'>, \n",
      "Optimizer:<class 'torch.optim.sgd.SGD'>, \n",
      "DataLoader:<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "====================\n",
      "After make_private(). Model:<class 'opacus.grad_sample.grad_sample_module.GradSampleModule'>, \n",
      "Optimizer:<class 'opacus.optimizers.optimizer.DPOptimizer'>, \n",
      "DataLoader:<class 'opacus.data_loader.DPDataLoader'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "print(\n",
    "    f\"Before make_private(). \"\n",
    "    f\"Model:{type(model)}, \\nOptimizer:{type(optimizer)}, \\nDataLoader:{type(data_loader)}\"\n",
    ")\n",
    "\n",
    "model, optimizer, data_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=data_loader,\n",
    "    max_grad_norm=1.0,\n",
    "    noise_multiplier=1.0,\n",
    ")\n",
    "\n",
    "print(\"=\"*20)\n",
    "\n",
    "print(\n",
    "    f\"After make_private(). \"\n",
    "    f\"Model:{type(model)}, \\nOptimizer:{type(optimizer)}, \\nDataLoader:{type(data_loader)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
