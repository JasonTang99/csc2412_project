{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "import os\n",
    "from time import time, sleep\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import opacus\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "from utils import generate_run_id, get_input_args, Args, parse_run_id\n",
    "from models import Discriminator_FC, Generator_MNIST, Weight_Clipper, G_weights_init, Generator_FC, Encoder_Mini, Decoder_Mini, VAE, Encoder_VAE, Decoder_VAE\n",
    "from data import load_MNIST\n",
    "from metrics import get_IS, get_FID\n",
    "from model_inversion import enc_fp, dec_fp, gen_fp\n",
    "from evaluate_metrics import last_num_models\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded public models\n"
     ]
    }
   ],
   "source": [
    "pub_G = Generator_FC(hidden_sizes=[256], nz=100).to(device)\n",
    "pub_G.load_state_dict(torch.load(gen_fp))\n",
    "\n",
    "pub_Dec = Decoder_Mini(latent_size=100).to(device)\n",
    "pub_Dec.load_state_dict(torch.load(dec_fp))\n",
    "\n",
    "pub_Enc = Encoder_Mini(latent_size=100).to(device)\n",
    "pub_Enc.load_state_dict(torch.load(enc_fp))\n",
    "\n",
    "pub_G.eval()\n",
    "pub_Dec.eval()\n",
    "pub_Enc.eval()\n",
    "print(\"Loaded public models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_multiplier</th>\n",
       "      <th>c_p</th>\n",
       "      <th>activation</th>\n",
       "      <th>lr</th>\n",
       "      <th>IS</th>\n",
       "      <th>FID</th>\n",
       "      <th>model_fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.092349</td>\n",
       "      <td>338.987852</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.004933</td>\n",
       "      <td>350.900943</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.064879</td>\n",
       "      <td>354.843270</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.017361</td>\n",
       "      <td>358.692219</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.005</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.335345</td>\n",
       "      <td>242.313955</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   noise_multiplier    c_p activation    lr        IS         FID  \\\n",
       "0              0.01  0.001       Tanh  0.02  1.092349  338.987852   \n",
       "1              0.01  0.001  LeakyReLU  0.01  1.004933  350.900943   \n",
       "2              0.01  0.001       Tanh  0.01  1.064879  354.843270   \n",
       "3              0.01  0.001  LeakyReLU  0.02  1.017361  358.692219   \n",
       "4              0.01  0.005  LeakyReLU  0.01  1.335345  242.313955   \n",
       "\n",
       "                                            model_fp  \n",
       "0  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  \n",
       "1  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  \n",
       "2  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  \n",
       "3  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  \n",
       "4  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ISs\n",
    "df_1 = pd.read_csv(\"vae_results.csv\")\n",
    "# Read FIDs\n",
    "df_2 = pd.read_csv(\"vae_FID.csv\")\n",
    "\n",
    "# Join df and df_2 on model_fp\n",
    "df = df_1.merge(df_2, on=\"model_fp\", suffixes=(\"\", \"_gan\"))\n",
    "# Drop non-48000 n_g\n",
    "df = df[df[\"n_g\"] == 48000]\n",
    "\n",
    "# Keep only the columns we want (noise_multiplier, activation, c_p, lr, model_fp, IS, FID)\n",
    "df = df[[\"noise_multiplier\", \"c_p\", \"activation\", \"lr\", \"IS\", \"FID\", \"model_fp\"]]\n",
    "df = df.sort_values(by=[\"noise_multiplier\",\"c_p\", \"FID\"])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_multiplier</th>\n",
       "      <th>c_p</th>\n",
       "      <th>activation</th>\n",
       "      <th>lr</th>\n",
       "      <th>IS</th>\n",
       "      <th>FID</th>\n",
       "      <th>model_fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.092349</td>\n",
       "      <td>338.987852</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.005</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.335345</td>\n",
       "      <td>242.313955</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.010</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.657780</td>\n",
       "      <td>178.152178</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.050</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.863078</td>\n",
       "      <td>125.267373</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.119791</td>\n",
       "      <td>341.618543</td>\n",
       "      <td>runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.05_0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   noise_multiplier    c_p activation    lr        IS         FID  \\\n",
       "0              0.01  0.001       Tanh  0.02  1.092349  338.987852   \n",
       "1              0.01  0.005  LeakyReLU  0.01  1.335345  242.313955   \n",
       "2              0.01  0.010  LeakyReLU  0.01  1.657780  178.152178   \n",
       "3              0.01  0.050  LeakyReLU  0.01  1.863078  125.267373   \n",
       "4              0.05  0.001       Tanh  0.02  1.119791  341.618543   \n",
       "\n",
       "                                            model_fp  \n",
       "0  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  \n",
       "1  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  \n",
       "2  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  \n",
       "3  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0....  \n",
       "4  runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.05_0....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by noise and c_p, and get the best FID\n",
    "df_best = df.groupby([\"noise_multiplier\", \"c_p\"]).first().reset_index()\n",
    "df_best = df_best.sort_values(by=[\"noise_multiplier\", \"c_p\"])\n",
    "df_best = df_best.reset_index(drop=True)\n",
    "df_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in list(df_best[\"model_fp\"].values):\n",
    "    os.system(\"cp -r {} runs_vae_tmp/\".format(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fp in list(df_best[\"model_fp\"].values):\n",
    "#     os.system(\"rm -rf {}\".format(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-grad_64_32_32_1_50.0_1e-06_0.2_0.25_0.01_0.5_64_0_48000_LeakyReLU_0.0 True\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.3_0.25_0.01_0.5_64_0_48000_LeakyReLU_0.0 True\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.4_0.25_0.01_0.5_64_0_48000_LeakyReLU_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.2_0.1_0.01_0.5_64_0_48000_LeakyReLU_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.3_0.1_0.01_0.5_64_0_48000_LeakyReLU_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.4_0.1_0.01_0.5_64_0_48000_LeakyReLU_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.2_0.25_0.01_0.5_64_0_48000_Tanh_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.3_0.25_0.01_0.5_64_0_48000_Tanh_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.4_0.25_0.01_0.5_64_0_48000_Tanh_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.2_0.1_0.01_0.5_64_0_48000_Tanh_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.3_0.1_0.01_0.5_64_0_48000_Tanh_0.0 False\n",
      "ae-grad_64_32_32_1_50.0_1e-06_0.4_0.1_0.01_0.5_64_0_48000_Tanh_0.0 False\n"
     ]
    }
   ],
   "source": [
    "hiddens = [64]\n",
    "noise_multipliers = [0.2, 0.3, 0.4] # [0.01, 0.05, 0.1]\n",
    "activations = [\"LeakyReLU\", \"Tanh\", ]\n",
    "c_ps = [0.25, 0.1] # [0.05, 0.01, 0.005, 0.001]\n",
    "lrs = [0.01] #  0.005]\n",
    "\n",
    "nz = 32\n",
    "n_d = 0\n",
    "n_g = 48000\n",
    "batch_size = 64\n",
    "from itertools import product\n",
    "for activation, c_p, noise_multiplier, lr in product(\n",
    "        activations, c_ps, noise_multipliers, lrs):\n",
    "    args = Args(\n",
    "        # Model Parameters\n",
    "        hidden=[64], nz=32, ngf=32, nc=1, activation=activation,\n",
    "        # Privacy Parameters\n",
    "        epsilon=50.0, delta=1e-6, noise_multiplier=noise_multiplier, c_p=c_p,\n",
    "        # Training Parameters\n",
    "        lr=lr, beta1=0.5, batch_size=batch_size, n_d=0, n_g=n_g, lambda_gp=0.0\n",
    "    )\n",
    "    # main(args, latent_type=\"ae_enc\")\n",
    "    run_id = \"ae-grad_\" + generate_run_id(args)\n",
    "    print(run_id, os.path.exists(\"runs_vae/{}\".format(run_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import pickle\n",
    "\n",
    "def calculate_epsilon_used(run_fp, delta=1e-5):\n",
    "    \"\"\"Calculates the epsilon used for a given noise_multiplier\n",
    "    We need to linearly extrapolate past a few thousand batches since\n",
    "        the accountant uses too much memory and gets killed\n",
    "    \"\"\"\n",
    "    run_id = run_fp.split(\"/\")[-1]\n",
    "    args = parse_run_id(run_id)\n",
    "\n",
    "    # Read in loss file\n",
    "    # Lines look like:\n",
    "    # Epsilon 200 68.85602575854573\n",
    "    # with open(f\"{run_fp}/losses.txt\", \"r\") as f:\n",
    "    #     lines = f.readlines()\n",
    "    # epsilons = []\n",
    "    # for line in lines:\n",
    "    #     if \"Epsilon\" in line:\n",
    "    #         batch_idx, eps = line.split(\" \")[1:]\n",
    "    #         epsilons.append([float(batch_idx), float(eps)])\n",
    "    \n",
    "\n",
    "    accts = sorted([\n",
    "        (int(fp.split(\"_\")[-1].strip(\".pt\")), fp) \n",
    "        for fp in os.listdir(run_fp) if fp.startswith(\"accountant\")\n",
    "    ])\n",
    "\n",
    "    epsilons = []\n",
    "    for batch_idx, acct_fp in accts:\n",
    "        if batch_idx > 20000:\n",
    "            print(\"Breaking\")\n",
    "            break\n",
    "        try:\n",
    "            print(batch_idx, \"Noise:\", args.noise_multiplier, \"Clip:\", args.c_p, acct_fp)\n",
    "            accountant = torch.load(f\"{run_fp}/{acct_fp}\")\n",
    "            print(run_fp, acct_fp)\n",
    "            curr_eps = accountant.get_epsilon(delta)\n",
    "            print(batch_idx, curr_eps)\n",
    "        except Exception as e:\n",
    "            print(\"Error, breaking\", e)\n",
    "            break\n",
    "        epsilons.append([batch_idx, curr_eps])\n",
    "\n",
    "        # If epsilon is too high, we can't use it\n",
    "        if curr_eps > 200:\n",
    "            if len(epsilons) == 1:\n",
    "                epsilons = []\n",
    "            print(\"Epsilon too high, breaking\")\n",
    "            break\n",
    "    # print(epsilons)\n",
    "\n",
    "    # Linearly interpolate to get the epsilon used\n",
    "    if len(epsilons) == 0:\n",
    "        f = interp1d(np.array([0, 1]), np.array([-1, -1]), kind=\"linear\", fill_value=\"extrapolate\")\n",
    "    else:\n",
    "        epsilons = np.array(epsilons)\n",
    "        f = interp1d(epsilons[:, 0], epsilons[:, 1], kind=\"linear\", fill_value=\"extrapolate\")\n",
    "    \n",
    "    # Pickle the function\n",
    "    with open(f\"{run_fp}/epsilon_used.pkl\", \"wb\") as file:\n",
    "        pickle.dump(f, file)\n",
    "    \n",
    "    return f(args.n_g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 Noise: 0.2 Clip: 0.5 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0 accountant_200.pt\n",
      "200 58.99997843029757\n",
      "400 Noise: 0.2 Clip: 0.5 accountant_400.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0 accountant_400.pt\n",
      "400 76.08746105795657\n",
      "600 Noise: 0.2 Clip: 0.5 accountant_600.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0 accountant_600.pt\n",
      "600 89.88315850500715\n",
      "800 Noise: 0.2 Clip: 0.5 accountant_800.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0 accountant_800.pt\n",
      "800 102.03902484103334\n",
      "1000 Noise: 0.2 Clip: 0.5 accountant_1000.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0 accountant_1000.pt\n",
      "1000 113.1689867808569\n",
      "1200 Noise: 0.2 Clip: 0.5 accountant_1200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0 accountant_1200.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m run_fp \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mruns_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m calculate_epsilon_used(run_fp)\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36mcalculate_epsilon_used\u001b[0;34m(run_fp, delta)\u001b[0m\n\u001b[1;32m     24\u001b[0m     accountant \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrun_fp\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00macct_fp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(run_fp, acct_fp)\n\u001b[0;32m---> 26\u001b[0m     curr_eps \u001b[39m=\u001b[39m accountant\u001b[39m.\u001b[39;49mget_epsilon(delta)\n\u001b[1;32m     27\u001b[0m     \u001b[39mprint\u001b[39m(batch_idx, curr_eps)\n\u001b[1;32m     28\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/prv.py:97\u001b[0m, in \u001b[0;36mPRVAccountant.get_epsilon\u001b[0;34m(self, delta, eps_error, delta_error)\u001b[0m\n\u001b[1;32m     95\u001b[0m     delta_error \u001b[39m=\u001b[39m delta \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[39m# we construct a discrete PRV from the history\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m dprv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_dprv(eps_error\u001b[39m=\u001b[39;49meps_error, delta_error\u001b[39m=\u001b[39;49mdelta_error)\n\u001b[1;32m     98\u001b[0m \u001b[39m# this discrete PRV can be used to directly estimate and bound epsilon\u001b[39;00m\n\u001b[1;32m     99\u001b[0m _, _, eps_upper \u001b[39m=\u001b[39m dprv\u001b[39m.\u001b[39mcompute_epsilon(delta, delta_error, eps_error)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/prv.py:126\u001b[0m, in \u001b[0;36mPRVAccountant._get_dprv\u001b[0;34m(self, eps_error, delta_error)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m# discretize and convolve prvs\u001b[39;00m\n\u001b[1;32m    125\u001b[0m dprvs \u001b[39m=\u001b[39m [discretize(tprv, domain) \u001b[39mfor\u001b[39;00m tprv \u001b[39min\u001b[39;00m tprvs]\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m compose_heterogeneous(\n\u001b[1;32m    127\u001b[0m     dprvs\u001b[39m=\u001b[39;49mdprvs, num_self_compositions\u001b[39m=\u001b[39;49mnum_self_compositions\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/analysis/prv/compose.py:58\u001b[0m, in \u001b[0;36mcompose_heterogeneous\u001b[0;34m(dprvs, num_self_compositions)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dprvs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(num_self_compositions):\n\u001b[1;32m     56\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdprvs and num_self_compositions must have the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m dprvs \u001b[39m=\u001b[39m [\n\u001b[1;32m     59\u001b[0m     _compose_fourier(dprv, num_self_composition)\n\u001b[1;32m     60\u001b[0m     \u001b[39mfor\u001b[39;00m dprv, num_self_composition \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dprvs, num_self_compositions)\n\u001b[1;32m     61\u001b[0m ]\n\u001b[1;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m _compose_convolution_tree(dprvs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/analysis/prv/compose.py:59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dprvs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(num_self_compositions):\n\u001b[1;32m     56\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdprvs and num_self_compositions must have the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m dprvs \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 59\u001b[0m     _compose_fourier(dprv, num_self_composition)\n\u001b[1;32m     60\u001b[0m     \u001b[39mfor\u001b[39;00m dprv, num_self_composition \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dprvs, num_self_compositions)\n\u001b[1;32m     61\u001b[0m ]\n\u001b[1;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m _compose_convolution_tree(dprvs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/analysis/prv/compose.py:14\u001b[0m, in \u001b[0;36m_compose_fourier\u001b[0;34m(dprv, num_self_composition)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dprv) \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only compose evenly sized discrete PRVs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m composed_pmf \u001b[39m=\u001b[39m irfft(rfft(dprv\u001b[39m.\u001b[39;49mpmf) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m num_self_composition)\n\u001b[1;32m     16\u001b[0m m \u001b[39m=\u001b[39m num_self_composition \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m num_self_composition \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/scipy/fft/_backend.py:25\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/scipy/fft/_pocketfft/basic.py:97\u001b[0m, in \u001b[0;36mc2r\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     94\u001b[0m     tmp, _ \u001b[39m=\u001b[39m _fix_shape_1d(tmp, (n\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, axis)\n\u001b[1;32m     96\u001b[0m \u001b[39m# Note: overwrite_x is not utilized\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[39mreturn\u001b[39;00m pfft\u001b[39m.\u001b[39;49mc2r(tmp, (axis,), n, forward, norm, \u001b[39mNone\u001b[39;49;00m, workers)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_fp = \"runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0\"\n",
    "calculate_epsilon_used(run_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fp = \"runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0\"\n",
    "calculate_epsilon_used(run_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 Noise: 0.1 Clip: 0.001 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.001_0.01_0.5_64_0_48000_LeakyReLU_0.0 accountant_200.pt\n",
      "200 293.5059794795981\n",
      "Epsilon too high, breaking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(-1.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_fp = \"runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.001_0.01_0.5_64_0_48000_LeakyReLU_0.0\"\n",
    "calculate_epsilon_used(run_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.001_0.01_0.5_64_0_48000_LeakyReLU_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.001_0.01_0.5_64_0_48000_Tanh_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.001_0.02_0.5_64_0_48000_Tanh_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.005_0.01_0.5_64_0_48000_Tanh_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.005_0.02_0.5_64_0_48000_LeakyReLU_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.005_0.02_0.5_64_0_48000_Tanh_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.01_0.01_0.5_64_0_48000_Tanh_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.01_0.02_0.5_64_0_48000_LeakyReLU_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.01_0.02_0.5_64_0_48000_Tanh_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.05_0.01_0.5_64_0_48000_Tanh_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.05_0.02_0.5_64_0_48000_LeakyReLU_0.0',\n",
       " 'runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.1_0.05_0.02_0.5_64_0_48000_Tanh_0.0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_runs_fps = []\n",
    "for run_id in os.listdir(\"runs_vae\"):\n",
    "    run_fp = f\"runs_vae/{run_id}\"\n",
    "    args = parse_run_id(run_id)\n",
    "    if run_id.startswith(\"ae-grad\") and \\\n",
    "            args.noise_multiplier >= 0.1 and \\\n",
    "            args.n_g > 20000 and \\\n",
    "            args.n_g < 50000:\n",
    "        valid_runs_fps.append(run_fp)\n",
    "valid_runs_fps = sorted(valid_runs_fps)\n",
    "valid_runs_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run_fp = \"runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.2_0.5_0.01_0.5_64_0_100000_LeakyReLU_0.0\"\n",
    "# calculate_epsilon_used(run_fp)\n",
    "\n",
    "valid_runs_fps = []\n",
    "for run_id in os.listdir(\"runs_vae\"):\n",
    "    run_fp = f\"runs_vae/{run_id}\"\n",
    "    args = parse_run_id(run_id)\n",
    "    if run_id.startswith(\"ae-grad\") and \\\n",
    "            args.noise_multiplier > 0 and \\\n",
    "            args.n_g > 20000 and \\\n",
    "            args.n_g < 50000:\n",
    "        valid_runs_fps.append(run_fp)\n",
    "valid_runs_fps = sorted(valid_runs_fps)\n",
    "\n",
    "len(valid_runs_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args(hidden=[64], nz=32, ngf=32, nc=1, epsilon=50.0, delta=1e-06, noise_multiplier=0.01, c_p=0.001, lr=0.01, beta1=0.5, batch_size=64, n_d=0, n_g=48000, activation='LeakyReLU', lambda_gp=0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_run_id(valid_runs_fps[0].split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m privacy_engine \u001b[39m=\u001b[39m PrivacyEngine()\n\u001b[1;32m      3\u001b[0m privacy_engine\u001b[39m.\u001b[39maccountant \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(acct_fp)\n\u001b[0;32m----> 4\u001b[0m privacy_engine\u001b[39m.\u001b[39;49mget_epsilon(\u001b[39m1e-5\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/privacy_engine.py:544\u001b[0m, in \u001b[0;36mPrivacyEngine.get_epsilon\u001b[0;34m(self, delta)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_epsilon\u001b[39m(\u001b[39mself\u001b[39m, delta):\n\u001b[1;32m    535\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39m    Computes the (epsilon, delta) privacy budget spent so far.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39m        Privacy budget (epsilon) expended so far.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccountant\u001b[39m.\u001b[39;49mget_epsilon(delta)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/prv.py:97\u001b[0m, in \u001b[0;36mPRVAccountant.get_epsilon\u001b[0;34m(self, delta, eps_error, delta_error)\u001b[0m\n\u001b[1;32m     95\u001b[0m     delta_error \u001b[39m=\u001b[39m delta \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[39m# we construct a discrete PRV from the history\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m dprv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_dprv(eps_error\u001b[39m=\u001b[39;49meps_error, delta_error\u001b[39m=\u001b[39;49mdelta_error)\n\u001b[1;32m     98\u001b[0m \u001b[39m# this discrete PRV can be used to directly estimate and bound epsilon\u001b[39;00m\n\u001b[1;32m     99\u001b[0m _, _, eps_upper \u001b[39m=\u001b[39m dprv\u001b[39m.\u001b[39mcompute_epsilon(delta, delta_error, eps_error)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/prv.py:125\u001b[0m, in \u001b[0;36mPRVAccountant._get_dprv\u001b[0;34m(self, eps_error, delta_error)\u001b[0m\n\u001b[1;32m    120\u001b[0m tprvs \u001b[39m=\u001b[39m [\n\u001b[1;32m    121\u001b[0m     TruncatedPrivacyRandomVariable(prv, domain\u001b[39m.\u001b[39mt_min, domain\u001b[39m.\u001b[39mt_max)\n\u001b[1;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m prv \u001b[39min\u001b[39;00m prvs\n\u001b[1;32m    123\u001b[0m ]\n\u001b[1;32m    124\u001b[0m \u001b[39m# discretize and convolve prvs\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m dprvs \u001b[39m=\u001b[39m [discretize(tprv, domain) \u001b[39mfor\u001b[39;00m tprv \u001b[39min\u001b[39;00m tprvs]\n\u001b[1;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m compose_heterogeneous(\n\u001b[1;32m    127\u001b[0m     dprvs\u001b[39m=\u001b[39mdprvs, num_self_compositions\u001b[39m=\u001b[39mnum_self_compositions\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/prv.py:125\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m tprvs \u001b[39m=\u001b[39m [\n\u001b[1;32m    121\u001b[0m     TruncatedPrivacyRandomVariable(prv, domain\u001b[39m.\u001b[39mt_min, domain\u001b[39m.\u001b[39mt_max)\n\u001b[1;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m prv \u001b[39min\u001b[39;00m prvs\n\u001b[1;32m    123\u001b[0m ]\n\u001b[1;32m    124\u001b[0m \u001b[39m# discretize and convolve prvs\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m dprvs \u001b[39m=\u001b[39m [discretize(tprv, domain) \u001b[39mfor\u001b[39;00m tprv \u001b[39min\u001b[39;00m tprvs]\n\u001b[1;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m compose_heterogeneous(\n\u001b[1;32m    127\u001b[0m     dprvs\u001b[39m=\u001b[39mdprvs, num_self_compositions\u001b[39m=\u001b[39mnum_self_compositions\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/analysis/prv/prvs.py:162\u001b[0m, in \u001b[0;36mdiscretize\u001b[0;34m(prv, domain)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdiscretize\u001b[39m(prv, domain: Domain) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DiscretePRV:\n\u001b[0;32m--> 162\u001b[0m     tC \u001b[39m=\u001b[39m domain\u001b[39m.\u001b[39;49mts\n\u001b[1;32m    163\u001b[0m     tL \u001b[39m=\u001b[39m tC \u001b[39m-\u001b[39m domain\u001b[39m.\u001b[39mdt \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    164\u001b[0m     tR \u001b[39m=\u001b[39m tC \u001b[39m+\u001b[39m domain\u001b[39m.\u001b[39mdt \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/opacus/accountants/analysis/prv/domain.py:58\u001b[0m, in \u001b[0;36mDomain.ts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mts\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mlinspace(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt_min, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt_max, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mlinspace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/numpy/core/function_base.py:135\u001b[0m, in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    132\u001b[0m     dtype \u001b[39m=\u001b[39m dt\n\u001b[1;32m    134\u001b[0m delta \u001b[39m=\u001b[39m stop \u001b[39m-\u001b[39m start\n\u001b[0;32m--> 135\u001b[0m y \u001b[39m=\u001b[39m _nx\u001b[39m.\u001b[39;49marange(\u001b[39m0\u001b[39;49m, num, dtype\u001b[39m=\u001b[39;49mdt)\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,) \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m ndim(delta))\n\u001b[1;32m    136\u001b[0m \u001b[39m# In-place multiplication y *= delta/div is faster, but prevents the multiplicant\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m# from overriding what class is produced, and thus prevents, e.g. use of Quantities,\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m# see gh-7142. Hence, we multiply in place only for standard scalar types.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m _mult_inplace \u001b[39m=\u001b[39m _nx\u001b[39m.\u001b[39misscalar(delta)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64"
     ]
    }
   ],
   "source": [
    "acct_fp = \"runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.001_0.01_0.5_64_0_48000_LeakyReLU_0.0/accountant_200.pt\"\n",
    "privacy_engine = PrivacyEngine()\n",
    "privacy_engine.accountant = torch.load(acct_fp)\n",
    "privacy_engine.get_epsilon(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.001_0.01_0.5_64_0_48000_LeakyReLU_0.0\n",
      "200 0.01 0.001 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.001_0.01_0.5_64_0_48000_LeakyReLU_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.001_0.01_0.5_64_0_48000_Tanh_0.0\n",
      "200 0.01 0.001 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.001_0.01_0.5_64_0_48000_Tanh_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.001_0.02_0.5_64_0_48000_LeakyReLU_0.0\n",
      "200 0.01 0.001 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.001_0.02_0.5_64_0_48000_LeakyReLU_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.005_0.01_0.5_64_0_48000_Tanh_0.0\n",
      "200 0.01 0.005 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.005_0.01_0.5_64_0_48000_Tanh_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.005_0.02_0.5_64_0_48000_LeakyReLU_0.0\n",
      "200 0.01 0.005 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.005_0.02_0.5_64_0_48000_LeakyReLU_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.005_0.02_0.5_64_0_48000_Tanh_0.0\n",
      "200 0.01 0.005 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.005_0.02_0.5_64_0_48000_Tanh_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.01_0.01_0.5_64_0_48000_Tanh_0.0\n",
      "200 0.01 0.01 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.01_0.01_0.5_64_0_48000_Tanh_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.01_0.02_0.5_64_0_48000_LeakyReLU_0.0\n",
      "200 0.01 0.01 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.01_0.02_0.5_64_0_48000_LeakyReLU_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.01_0.02_0.5_64_0_48000_Tanh_0.0\n",
      "200 0.01 0.01 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.01_0.02_0.5_64_0_48000_Tanh_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.05_0.01_0.5_64_0_48000_Tanh_0.0\n",
      "200 0.01 0.05 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.05_0.01_0.5_64_0_48000_Tanh_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.05_0.02_0.5_64_0_48000_LeakyReLU_0.0\n",
      "200 0.01 0.05 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.05_0.02_0.5_64_0_48000_LeakyReLU_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.05_0.02_0.5_64_0_48000_Tanh_0.0\n",
      "200 0.01 0.05 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.01_0.05_0.02_0.5_64_0_48000_Tanh_0.0 accountant_200.pt\n",
      "Error, breaking Unable to allocate 74.1 GiB for an array with shape (9945573802,) and data type float64\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.05_0.001_0.01_0.5_64_0_48000_LeakyReLU_0.0\n",
      "200 0.05 0.001 accountant_200.pt\n",
      "runs_vae/ae-grad_64_32_32_1_50.0_1e-06_0.05_0.001_0.01_0.5_64_0_48000_LeakyReLU_0.0 accountant_200.pt\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for run_fp in valid_runs_fps:\n",
    "    print(run_fp)\n",
    "    calculate_epsilon_used(run_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the epsilon used for each run\n",
    "idx = 0\n",
    "print(calculate_epsilon_used(valid_runs_fps[idx]))\n",
    "# if not os.path.exists(f\"{run_fp}/epsilon_used.pkl\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "print(calculate_epsilon_used(valid_runs_fps[idx]))\n",
    "idx = 2\n",
    "print(calculate_epsilon_used(valid_runs_fps[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 10000, 200)\n",
    "# Load the function\n",
    "with open(f\"{run_fp}/epsilon_used.pkl\", \"rb\") as file:\n",
    "    f = pickle.load(file)\n",
    "plt.plot(xs, f(xs), 'k', lw=3, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(G, args, latent_type=None, plot=True, batch_size=32, seed=False):\n",
    "    if seed:\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "    # Generate Sample Images\n",
    "    noise = torch.randn(batch_size, args.nz).to(device)\n",
    "    if latent_type == \"wgan\":\n",
    "        output = G(noise)\n",
    "        fake = pub_G(output)\n",
    "    elif latent_type == \"ae\":\n",
    "        output = G(noise)\n",
    "        fake = pub_Dec(output)\n",
    "    else:\n",
    "        fake = G(noise)\n",
    "    fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "    \n",
    "    # Plot Sample Images\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(4, 8, figsize=(10, 5))\n",
    "        for i in range(4):\n",
    "            for j in range(8):\n",
    "                ax[i, j].imshow(fake[i*8+j][0].detach().cpu().numpy(), cmap='gray')\n",
    "                ax[i, j].axis('off')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructed(G, args, latent_type=None, r0=(-10, 10), r1=(-10, 10), n=12):\n",
    "    # Setup function\n",
    "    if latent_type == \"wgan\":\n",
    "        G_fn = lambda x: pub_G(G(x))\n",
    "    elif latent_type == \"ae\":\n",
    "        G_fn = lambda x: pub_Dec(G(x))\n",
    "    else:\n",
    "        G_fn = G\n",
    "\n",
    "    w = 28\n",
    "    img = np.zeros((n*w, n*w))\n",
    "    for i, y in enumerate(np.linspace(*r1, n)):\n",
    "        for j, x in enumerate(np.linspace(*r0, n)):\n",
    "            z = torch.Tensor([[x, y]]).to(device)\n",
    "            x_hat = G_fn(z)\n",
    "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n",
    "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n",
    "    plt.imshow(img, extent=[*r0, *r1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_during_training(run_fp, end=50000, step=5000):\n",
    "    # Parse args\n",
    "    run_id = run_fp.split(\"/\")[-1]\n",
    "    args = parse_run_id(run_id)\n",
    "\n",
    "    imgs = []\n",
    "    for j in range(step, end + 1, step):\n",
    "        gen_fp = f\"vae_{j}.pt\"\n",
    "        gen_fp = os.path.join(run_fp, gen_fp)\n",
    "\n",
    "        # Check if model exists\n",
    "        if not os.path.exists(gen_fp):\n",
    "            print(\"Model does not exist\", gen_fp)\n",
    "            raise ValueError(\"Model does not exist\")\n",
    "\n",
    "        vae = VAE(\n",
    "            Encoder_VAE(args.hidden, latent_size=args.nz), \n",
    "            Decoder_VAE(args.hidden, latent_size=args.nz)\n",
    "        ).to(device)\n",
    "        vae.load_state_dict(torch.load(gen_fp))\n",
    "        vae.eval()\n",
    "\n",
    "        G = vae.decoder\n",
    "        G.eval()\n",
    "\n",
    "        fake = generate_samples(\n",
    "            G, args, latent_type=\"wgan\" if run_id.startswith(\"wgan\") else \"ae\", \n",
    "            plot=False, batch_size=10, seed=True\n",
    "        )\n",
    "        imgs.append(fake)\n",
    "    \n",
    "    # Plot Sample Images\n",
    "    n = len(imgs)\n",
    "    fig, ax = plt.subplots(10, n)\n",
    "    for i in range(10):\n",
    "        for j in range(n):\n",
    "            ax[i, j].imshow(imgs[j][i][0].detach().cpu().numpy(), cmap='gray')\n",
    "            ax[i, j].axis('off')\n",
    "            if i == 0:\n",
    "                ax[i, j].set_title(f\"{(j+1)*step}\", color=\"white\", fontsize=9)\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.patch.set_facecolor('black')\n",
    "    fig.suptitle(f\"Samples during training epochs\", color=\"white\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_folder = \"runs_vae\"\n",
    "run_id = \"ae-grad_64_32_32_1_50.0_1e-06_0.0_1.0_0.01_0.5_64_0_100000_LeakyReLU_0.0\"\n",
    "\n",
    "run_fp = os.path.join(run_folder, run_id)\n",
    "print(run_id)\n",
    "\n",
    "samples_during_training(run_fp, end=100000, step=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_folder = \"runs_vae\"\n",
    "run_ids = os.listdir(run_folder)\n",
    "for i in range(len(run_ids)):\n",
    "    run_id = run_ids[i]\n",
    "    run_fp = os.path.join(run_folder, run_id)\n",
    "    args = parse_run_id(run_id)\n",
    "\n",
    "    # if args.lr != 0.1:\n",
    "    #     continue\n",
    "    # if args.n_g != 50000:\n",
    "    #     continue\n",
    "    # c_ps = [1.0, 2.0, 4.0, 8.0, 16.0, 32.0]\n",
    "    # if args.c_p > 32.0:\n",
    "    #     continue\n",
    "    # if args.c_p != 0.05:\n",
    "    #     continue\n",
    "    if args.noise_multiplier == 0.0:\n",
    "        continue\n",
    "    if args.batch_size != 64:\n",
    "        continue\n",
    "    if args.n_g != 48000:\n",
    "        continue\n",
    "\n",
    "    print(f\"Noise: {args.noise_multiplier}, Clip: {args.c_p}\")\n",
    "\n",
    "    gen_fp = last_num_models(run_fp, num=1, query=\"vae\")[0]\n",
    "    # gen_fp = \"vae_48000.pt\"\n",
    "    print(run_id + gen_fp)\n",
    "\n",
    "    gen_fp = os.path.join(run_fp, gen_fp)\n",
    "\n",
    "    # Check if exists\n",
    "    if not os.path.exists(gen_fp):\n",
    "        print(\"Generator model not found\")\n",
    "        continue\n",
    "    \n",
    "    vae = VAE(\n",
    "        Encoder_VAE(args.hidden, latent_size=args.nz), \n",
    "        Decoder_VAE(args.hidden, latent_size=args.nz)\n",
    "    ).to(device)\n",
    "    vae.load_state_dict(torch.load(gen_fp))\n",
    "    vae.eval()\n",
    "\n",
    "    G = vae.decoder\n",
    "    G.eval()\n",
    "\n",
    "    generate_samples(G, args, latent_type=\"wgan\" if run_id.startswith(\"wgan\") else \"ae\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id = \"/home/jason/p2/runs_latent/wgan_96_64_32_1_50.0_1e-06_0.0_0.01_5e-05_0.5_64_1_50000_LeakyReLU_0.0\"\n",
    "\n",
    "print no\n",
    "run_ids = os.listdir(\"runs_latent\")\n",
    "for i in range(len(run_ids)):\n",
    "    # run_ids[i] = os.path.join(\"runs_latent\", run_ids[i])\n",
    "    run_id = run_ids[i]\n",
    "    print(run_id)\n",
    "\n",
    "    run_id = run_id.split(\"/\")[-1]\n",
    "    run_fp = os.path.join('runs_latent/', run_id)\n",
    "    args = parse_run_id(run_id)\n",
    "\n",
    "    gen_fp = os.path.join(run_fp, 'netG_48000.pt')\n",
    "    # Check if exists\n",
    "    if not os.path.exists(gen_fp):\n",
    "        print(\"Generator model not found\")\n",
    "        continue\n",
    "\n",
    "    G = Generator_FC(args.hidden, args.nz, output_size=(100,)).to(device)\n",
    "    G.load_state_dict(torch.load(gen_fp))\n",
    "    G.eval()\n",
    "\n",
    "    generate_samples(G, args, latent_type=\"wgan\" if run_id.startswith(\"wgan\") else \"ae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating samples from gradient ascent\n",
    "from model_inversion import gradient_ascent, projected_gradient_ascent\n",
    "\n",
    "labeling_loader, public_loader, private_loader, test_loader = load_MNIST(10)\n",
    "\n",
    "# Get a single batch of private images\n",
    "imgs, _ = next(iter(private_loader))\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_list = [100, 1000, 10000, 100000, 200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.to(device)\n",
    "# Use pub_Enc and pub_Dec to encode/decode images\n",
    "imgs_enc = pub_Dec(pub_Enc(imgs)).detach().cpu()\n",
    "\n",
    "imgs_dec = []\n",
    "imgs_gen = []\n",
    "for iterations in iterations_list:\n",
    "    # Perform gradient ascent\n",
    "    latent_dec = gradient_ascent(\n",
    "        pub_Dec, imgs, latent_dim=100, start_lr=200,\n",
    "        iterations=iterations)\n",
    "\n",
    "    # Perform projected gradient ascent\n",
    "    latent_gen = projected_gradient_ascent(\n",
    "        pub_G, imgs, latent_dim=100, start_lr=200,\n",
    "        iterations=iterations, z_0_mult=1)\n",
    "    \n",
    "    # Decode the latent vectors\n",
    "    imgs_dec.append(pub_Dec(latent_dec).detach().cpu())\n",
    "    imgs_gen.append(pub_G(latent_gen).detach().cpu())\n",
    "imgs = imgs.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images\n",
    "fig, ax = plt.subplots(10, 12)\n",
    "rotation = 90\n",
    "# Original images\n",
    "for i in range(10):\n",
    "    ax[i, 0].imshow(imgs[i][0].detach().cpu().numpy(), cmap='gray')\n",
    "    ax[i, 0].axis('off')\n",
    "    if i == 0:\n",
    "        # Rotated title\n",
    "        ax[i, 0].set_title(\"Original\", color=\"white\", fontsize=9, rotation=rotation)\n",
    "# Decoded images\n",
    "for i in range(10):\n",
    "    ax[i, 1].imshow(imgs_enc[i][0].detach().cpu().numpy(), cmap='gray')\n",
    "    ax[i, 1].axis('off')\n",
    "    if i == 0:\n",
    "        ax[i, 1].set_title(\"ae-enc\", color=\"white\", fontsize=9, rotation=rotation)\n",
    "# Various iterations settings of gradient ascent (5 settings)\n",
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        ax[i, j+2].imshow(imgs_dec[j][i][0].detach().cpu().numpy(), cmap='gray')\n",
    "        ax[i, j+2].axis('off')\n",
    "        if i == 0:\n",
    "            ax[i, j+2].set_title(f\"ae-grad {iterations_list[j]}k\", color=\"white\", fontsize=9, rotation=rotation)\n",
    "# Various iterations settings of projected gradient ascent (5 settings)\n",
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        ax[i, j+7].imshow(imgs_gen[j][i][0].detach().cpu().numpy(), cmap='gray')\n",
    "        ax[i, j+7].axis('off')\n",
    "        if i == 0:\n",
    "            ax[i, j+7].set_title(f\"wgan {iterations_list[j]}k\", color=\"white\", fontsize=9, rotation=rotation)\n",
    "# Black background\n",
    "fig.patch.set_facecolor('black')\n",
    "# Remove the white space around the plots\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_latent\n",
    "# Seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Load Latent Vectors\n",
    "loader_ae_enc = load_latent(16, data_fp=\"data/ae_enc_latent_dataset.pt\")\n",
    "loader_ae_grad = load_latent(16, data_fp=\"data/ae_grad_latent_dataset.pt\")\n",
    "loader_wgan = load_latent(16, data_fp=\"data/wgan_latent_dataset.pt\")\n",
    "\n",
    "# Grab a single batch\n",
    "batch_ae_enc = next(iter(loader_ae_enc))[0]\n",
    "batch_ae_grad = next(iter(loader_ae_grad))[0]\n",
    "batch_wgan = next(iter(loader_wgan))[0]\n",
    "\n",
    "# Latent space to image space\n",
    "images_ae_enc = pub_Dec(batch_ae_enc)\n",
    "images_ae_grad = pub_Dec(batch_ae_grad)\n",
    "images_wgan = pub_G(batch_wgan)\n",
    "\n",
    "# Plot all images of a batch\n",
    "def plot_batch(images):\n",
    "    fig, ax = plt.subplots(4, 4)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ax[i, j].imshow(images[i*4 + j][0].detach().cpu().numpy(), cmap='gray')\n",
    "            ax[i, j].axis('off')\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.patch.set_facecolor('black')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_batch(images_ae_enc)\n",
    "plot_batch(images_ae_grad)\n",
    "plot_batch(images_wgan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, (data, ) in enumerate(train_loader):\n",
    "    # Print difference between item 0 and 1\n",
    "    print(data.shape)\n",
    "    print(torch.mean(data[0] - data[1]))\n",
    "\n",
    "    # Add noise to data\n",
    "    data = data + torch.randn_like(data)\n",
    "    \n",
    "    # Decode\n",
    "    fake = pub_Dec(data)\n",
    "    fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "\n",
    "    # Plot Sample Images\n",
    "    fig, ax = plt.subplots(4, 8, figsize=(10, 5))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            ax[i, j].imshow(fake[i*8+j][0].detach().cpu().numpy(), cmap='gray')\n",
    "            ax[i, j].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generator\n",
    "# run_id = \"/home/jason/p2/runs/private_16-12_100_32_1_inf_1e-06_0.0_0.01_0.0001_0.5_64_5_200000_LeakyReLU\" # decent\n",
    "run_id = \"/home/jason/p2/runs/private_16-12_100_32_1_inf_1e-06_0.4_0.005_0.0001_0.5_64_4_500000_LeakyReLU\" # better\n",
    "run_id = \"/home/jason/p2/runs/16-12_100_32_1_38.0_1e-06_0.05_0.01_0.0001_0.5_64_5_200000_LeakyReLU\" # somewhat reasonable noised\n",
    "run_id = \"/home/jason/p2/runs_gen_fc_3/public_128_100_32_1_inf_1e-06_0.0_0.01_5e-05_0.0_64_3_500000_LeakyReLU_0.0\"\n",
    "run_id = \"/home/jason/p2/runs_gen_fc_3/public_256_100_32_1_inf_1e-06_0.0_0.01_5e-05_0.0_64_3_500000_LeakyReLU_0.0\"\n",
    "\n",
    "run_id = run_id.split(\"/\")[-1]\n",
    "run_fp = os.path.join('runs_gen_fc_3/', run_id)\n",
    "args = parse_run_id(run_id)\n",
    "\n",
    "for i in range(500000, 500000 + 1, 10000):\n",
    "    gen_fp = os.path.join(run_fp, 'netG_{}.pt'.format(i))\n",
    "    if os.path.exists(gen_fp):\n",
    "        print(\"Loading {}\".format(gen_fp))\n",
    "\n",
    "        G = Generator_FC([256], args.nz).to(device)\n",
    "        G.load_state_dict(torch.load(gen_fp))\n",
    "        G.eval()\n",
    "\n",
    "        generate_samples(G, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seeding\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "activation = 'LeakyReLU'\n",
    "args = Args(\n",
    "    # Model Parameters\n",
    "    hidden=[16, 12], nz=100, ngf=32, nc=1, activation=activation,\n",
    "    # Privacy Parameters\n",
    "    epsilon=50.0, delta=1e-6, noise_multiplier=0.3, c_p=0.01, \n",
    "    # Training Parameters\n",
    "    lr=1e-3, beta1=0.5, batch_size=16, n_d=3, n_g=int(1e4), lambda_gp=10.0,\n",
    ")\n",
    "\n",
    "# Generate Run ID\n",
    "run_id = generate_run_id(args)\n",
    "\n",
    "\n",
    "run_id = \"public_16-12_100_32_1_inf_1e-06_0.4_0.005_0.0001_0.5_64_4_300000_LeakyReLU\"\n",
    "# run_id = \"16-12_100_32_1_inf_1e-06_0.4_0.005_0.0005_0.5_64_5_50000\"\n",
    "# /home/jason/p2/runs/16-12_100_32_1_inf_1e-06_0.4_0.005_0.0005_0.5_64_5_50000\n",
    "# run_id = \"16-12_100_32_1_50.0_1e-06_0.6_0.005_0.0001_0.5_64_4_300000_Tanh\"\n",
    "# run_id = \"16-12_100_32_1_50.0_1e-06_0.6_0.005_0.0001_0.5_64_5_300000_Tanh\"\n",
    "run_id = \"16-12_100_32_1_50.0_1e-06_0.2_0.005_0.0001_0.5_64_4_300000_Tanh\"\n",
    "\n",
    "# Create Folder Path\n",
    "run_fp = os.path.join('runs/', run_id)\n",
    "run_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = os.listdir(\"runs_gen_fc/\")\n",
    "len(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args\n",
    "# 3,4,6*,8,9,10*,13*,16,19,20\n",
    "# Args(hidden=[128], nz=50, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.005, lr=5e-05, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.01, lr=0.0005, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# * Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.005, lr=5e-05, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.01, lr=5e-05, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.005, lr=5e-05, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# * Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.005, lr=0.0005, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# * Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.01, lr=5e-05, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=50, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.01, lr=5e-05, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.005, lr=0.0005, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.01, lr=0.0005, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad\n",
    "args\n",
    "# 0,1,2,5,7,11,12,14,15,17,18,21\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.02, lr=5e-05, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.0, lr=0.0005, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=10.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.02, lr=0.0005, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=50, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.02, lr=5e-05, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.02, lr=5e-05, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.02, lr=0.0005, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.0, lr=0.0005, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=10.0)\n",
    "# Args(hidden=[128], nz=50, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.0, lr=5e-05, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=10.0)\n",
    "# Args(hidden=[128], nz=50, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.02, lr=5e-05, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=0.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.0, lr=5e-05, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=10.0)\n",
    "# Args(hidden=[128], nz=50, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.0, lr=5e-05, beta1=0.0, batch_size=64, n_d=3, n_g=100000, activation='LeakyReLU', lambda_gp=10.0)\n",
    "# Args(hidden=[128], nz=100, ngf=32, nc=1, epsilon='inf', delta=1e-06, noise_multiplier=0.0, c_p=0.0, lr=5e-05, beta1=0.0, batch_size=64, n_d=5, n_g=100000, activation='LeakyReLU', lambda_gp=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 12\n",
    "fp = os.path.join(\"runs_gen_fc/\", fps[idx])\n",
    "args = parse_run_id(fps[idx])\n",
    "\n",
    "for i in range(0, 100000 + 1, 20000):\n",
    "    gen_fp = os.path.join(fp, 'netG_{}.pt'.format(i))\n",
    "    if os.path.exists(gen_fp):\n",
    "        print(\"Loading {}\".format(gen_fp))\n",
    "        \n",
    "        G = Generator_FC([128], args.nz).to(device)\n",
    "        G.load_state_dict(torch.load(gen_fp))\n",
    "        G.eval()\n",
    "\n",
    "        generate_samples(G, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(run_fp):\n",
    "    # Read loss.txt\n",
    "    loss_fp = os.path.join(run_fp, 'loss.txt')\n",
    "    epsilons = []\n",
    "    d_loss, g_loss = [], []\n",
    "\n",
    "    with open(loss_fp, 'r') as f:\n",
    "        loss = f.read().splitlines()\n",
    "        for i in range(len(loss)):\n",
    "            if \"time\" in loss[i]:\n",
    "                continue\n",
    "            idx, l = loss[i].split(\", \")\n",
    "\n",
    "            if \".\" in idx:\n",
    "                # Discriminator_FC Loss\n",
    "                idx = int(float(idx))\n",
    "                d_loss.append((idx, float(l)))\n",
    "            else:\n",
    "                # Generator Loss\n",
    "                idx = int(float(idx))\n",
    "                g_loss.append((idx, float(l)))\n",
    "\n",
    "    # Graph Loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Generator and Discriminator_FC Loss During Training\")\n",
    "    plt.plot(*zip(*d_loss), label=\"Discriminator_FC\")\n",
    "    plt.plot(*zip(*g_loss), label=\"Generator\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    # Only show first 100 epochs\n",
    "    # plt.xlim(-10, 20000)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2048 fake images\n",
    "noise = torch.randn(2048, 100).to(device)\n",
    "fake = G(noise)\n",
    "fake = fake.view(fake.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Inception Score\n",
    "IS = get_IS(fake)\n",
    "print(\"Inception Score:\", IS)\n",
    "\n",
    "# Calculate Frechet Inception Distance\n",
    "FID = get_FID(fake)\n",
    "print(\"Frechet Inception Distance:\", FID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15e8192faefa7c4df086f69d5df89c8d0b9f28f8905c5b10f9ee705b3f14aede"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
