{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "import os\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import opacus\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "from utils import generate_run_id, get_input_args, Args\n",
    "from models import Discriminator, Generator_MNIST, Weight_Clipper, G_weights_init\n",
    "from data import load_MNIST\n",
    "from metrics import get_IS, get_FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seeding\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "activation = 'LeakyReLU'\n",
    "args = Args(\n",
    "    # Model Parameters\n",
    "    hidden=[16, 12], nz=100, ngf=32, nc=1, activation=activation,\n",
    "    # Privacy Parameters\n",
    "    epsilon=50.0, delta=1e-6, noise_multiplier=0.3, c_p=0.01, \n",
    "    # Training Parameters\n",
    "    lr=1e-3, beta1=0.5, batch_size=16, n_d=3, n_g=int(1e4), lambda_gp=10.0,\n",
    ")\n",
    "\n",
    "# Generate Run ID\n",
    "run_id = generate_run_id(args)\n",
    "\n",
    "\n",
    "run_id = \"public_16-12_100_32_1_inf_1e-06_0.4_0.005_0.0001_0.5_64_4_300000_LeakyReLU\"\n",
    "# run_id = \"16-12_100_32_1_inf_1e-06_0.4_0.005_0.0005_0.5_64_5_50000\"\n",
    "# /home/jason/p2/runs/16-12_100_32_1_inf_1e-06_0.4_0.005_0.0005_0.5_64_5_50000\n",
    "# run_id = \"16-12_100_32_1_50.0_1e-06_0.6_0.005_0.0001_0.5_64_4_300000_Tanh\"\n",
    "# run_id = \"16-12_100_32_1_50.0_1e-06_0.6_0.005_0.0001_0.5_64_5_300000_Tanh\"\n",
    "run_id = \"16-12_100_32_1_50.0_1e-06_0.2_0.005_0.0001_0.5_64_4_300000_Tanh\"\n",
    "\n",
    "# Create Folder Path\n",
    "run_fp = os.path.join('runs/', run_id)\n",
    "run_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# run_id = \"16-12_100_32_1_50.0_1e-06_0.6_0.005_0.0001_0.5_32_4_500000\"\n",
    "run_fp = os.path.join('runs/', run_id)\n",
    "\n",
    "# Read loss.txt\n",
    "# 4 lines of discriminator loss, 1 line of generator loss\n",
    "# Seperate discriminator loss and generator loss\n",
    "loss_fp = os.path.join(run_fp, 'loss.txt')\n",
    "epsilons = []\n",
    "d_loss, g_loss = [], []\n",
    "\n",
    "with open(loss_fp, 'r') as f:\n",
    "    loss = f.read().splitlines()\n",
    "    for i in range(len(loss)):\n",
    "        if \"time\" in loss[i]:\n",
    "            continue\n",
    "        idx, l = loss[i].split(\", \")\n",
    "\n",
    "        if \".\" in idx:\n",
    "            # Discriminator Loss\n",
    "            idx = int(float(idx))\n",
    "            d_loss.append((idx, float(l)))\n",
    "        else:\n",
    "            # Generator Loss\n",
    "            idx = int(float(idx))\n",
    "            g_loss.append((idx, float(l)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss[197: 201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(*zip(*d_loss), label=\"Discriminator\")\n",
    "plt.plot(*zip(*g_loss), label=\"Generator\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Only show first 100 epochs\n",
    "# plt.xlim(-10, 20000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(fp):\n",
    "    G = Generator_MNIST(nz=args.nz, ngf=args.ngf, nc=args.nc).to(device)\n",
    "    G.load_state_dict(torch.load(os.path.join(run_fp, fp)))\n",
    "    G.eval()\n",
    "    # Generate Sample Images\n",
    "    noise = torch.randn(32, 100, 1, 1).to(device)\n",
    "    fake = G(noise)\n",
    "    fake = fake.view(fake.size(0), 1, 28, 28)\n",
    "    print(torch.min(fake), torch.max(fake))\n",
    "\n",
    "    # Plot Sample Images\n",
    "    fig, ax = plt.subplots(4, 8, figsize=(10, 5))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            ax[i, j].imshow(fake[i*8+j][0].detach().cpu().numpy(), cmap='gray')\n",
    "            ax[i, j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generator\n",
    "# run_id = \"/home/jason/p2/runs/private_16-12_100_32_1_inf_1e-06_0.0_0.01_0.0001_0.5_64_5_200000_LeakyReLU\" # decent\n",
    "run_id = \"/home/jason/p2/runs/private_16-12_100_32_1_inf_1e-06_0.4_0.005_0.0001_0.5_64_4_500000_LeakyReLU\" # better\n",
    "run_id = \"/home/jason/p2/runs/16-12_100_32_1_38.0_1e-06_0.05_0.01_0.0001_0.5_64_5_200000_LeakyReLU\" # somewhat reasonable noised\n",
    "\n",
    "run_id = run_id.split(\"/\")[-1]\n",
    "run_fp = os.path.join('runs/', run_id)\n",
    "\n",
    "for i in range(0, 300000 + 1, 2000):\n",
    "    fp = 'netG_{}.pt'.format(i)\n",
    "    if os.path.exists(os.path.join(run_fp, fp)):\n",
    "        print(fp)\n",
    "        generate_samples(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Discriminator\n",
    "run_id = \"/home/jason/p2/runs/private_16-12_100_32_1_inf_1e-06_0.4_0.005_0.0001_0.5_64_4_500000_LeakyReLU\" # better\n",
    "run_id = run_id.split(\"/\")[-1]\n",
    "run_fp = os.path.join('runs/', run_id)\n",
    "\n",
    "from models import Discriminator_MNIST\n",
    "D = Discriminator_MNIST(nc=args.nc, ndf=args.ngf).to(device)\n",
    "D.load_state_dict(torch.load(os.path.join(run_fp, 'netD_500000.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2048 fake images\n",
    "noise = torch.randn(2048, 100, 1, 1).to(device)\n",
    "fake = G(noise)\n",
    "fake = fake.view(fake.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Inception Score\n",
    "IS = get_IS(fake)\n",
    "print(\"Inception Score:\", IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Frechet Inception Distance\n",
    "FID = get_FID(fake)\n",
    "print(\"Frechet Inception Distance:\", FID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15e8192faefa7c4df086f69d5df89c8d0b9f28f8905c5b10f9ee705b3f14aede"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
